import random
import re
from pathlib import Path
from datasets import load_dataset
from typing import TypedDict, Tuple, Dict, List, Optional, Any

# -----------------------------
# Dataset loading
# -----------------------------    
def init_dataset(
    humaneval_dset_name: str = "openai/openai_humaneval",
    max_dataset_size: int | None = None,
    train_ratio: float = 0.6,
    val_ratio: float = 0.2,
    test_ratio: float = 0.2
) -> tuple[list[dict], list[dict], list[dict]]:
    """
    HumanEval ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  í›ˆë ¨/ê²€ì¦/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        humaneval_dset_name: HumanEval ë°ì´í„°ì…‹ ì´ë¦„
        max_dataset_size: ìµœëŒ€ ë°ì´í„°ì…‹ í¬ê¸° (Noneì´ë©´ ì „ì²´ ì‚¬ìš©)
        train_ratio: í›ˆë ¨ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.6)
        val_ratio: ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        test_ratio: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)
        
    Returns:
        tuple: (trainset, valset, testset) - ê°ê° HumanEvalDataInst ë¦¬ìŠ¤íŠ¸
        
    Raises:
        ValueError: ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë˜ëŠ” ë¹„ìœ¨ í•©ì´ 1.0ì´ ì•„ë‹Œ ê²½ìš°
        ImportError: datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
    """

    # ë¹„ìœ¨ ê²€ì¦
    ratio_sum = train_ratio + val_ratio + test_ratio
    if not (0.99 <= ratio_sum <= 1.01):  # ë¶€ë™ì†Œìˆ˜ì  ì˜¤ì°¨ í—ˆìš©
        raise ValueError(f"ë¹„ìœ¨ì˜ í•©ì´ 1.0ì´ì–´ì•¼ í•©ë‹ˆë‹¤. í˜„ì¬: {ratio_sum}")
    
    if not all(0 <= ratio <= 1 for ratio in [train_ratio, val_ratio, test_ratio]):
        raise ValueError("ëª¨ë“  ë¹„ìœ¨ì€ 0ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    train_split = []
    test_split = []

    try:
        # Load the HumanEval dataset
        load_dataset_result = load_dataset(humaneval_dset_name, split="test")
        
        # Convert to list for manipulation
        all_data = list(load_dataset_result)
        
        if not all_data:
            raise ValueError(f"Empty dataset loaded from {humaneval_dset_name}")
        
        # ë°ì´í„°ì…‹ í¬ê¸° ì œí•œ ì ìš©
        if max_dataset_size is not None and max_dataset_size > 0:
            all_data = all_data[:max_dataset_size]
            print(f"ğŸ“Š ë°ì´í„°ì…‹ í¬ê¸°ë¥¼ {max_dataset_size}ê°œë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤.")
        
        print(f"ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸°: {len(all_data)}ê°œ")
        random.Random(0).shuffle(all_data)
        
    except ImportError as e:
        raise ImportError(
            "datasets library is required. Install with: pip install datasets"
        ) from e
    except Exception as e:
        raise ValueError(f"Failed to load dataset {humaneval_dset_name}: {e}") from e
    
    # ë¹„ìœ¨ ê¸°ë°˜ ë°ì´í„° ë¶„í•  (ìµœì†Œ 1ê°œì”©ì€ ë³´ì¥)
    total_size = len(all_data)
    train_size = max(1, int(total_size * train_ratio))
    val_size = max(1, int(total_size * val_ratio))
    test_size = max(1, total_size - train_size - val_size)  # ë‚˜ë¨¸ì§€ëŠ” í…ŒìŠ¤íŠ¸ ì„¸íŠ¸
    
    # ì´ í¬ê¸°ê°€ 3ê°œ ë¯¸ë§Œì¸ ê²½ìš° ì¡°ì •
    if total_size < 3:
        train_size = 1
        val_size = 1 if total_size >= 2 else 0
        test_size = total_size - train_size - val_size
    
    # ë¶„í•  ì¸ë±ìŠ¤ ê³„ì‚°
    train_end = train_size
    val_end = train_size + val_size
    
    train_data = all_data[:train_end]
    val_data = all_data[train_end:val_end]
    test_data = all_data[val_end:]
    
    print(f"ğŸ“Š ë°ì´í„° ë¶„í•  ê²°ê³¼:")
    print(f"   - í›ˆë ¨ ì„¸íŠ¸: {len(train_data)}ê°œ ({len(train_data)/total_size*100:.1f}%)")
    print(f"   - ê²€ì¦ ì„¸íŠ¸: {len(val_data)}ê°œ ({len(val_data)/total_size*100:.1f}%)")
    print(f"   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸: {len(test_data)}ê°œ ({len(test_data)/total_size*100:.1f}%)")
    
    # ë°ì´í„° ë³€í™˜ í•¨ìˆ˜
    def convert_to_humaneval_format(data_items: list) -> list[dict]:
        """HumanEval ë°ì´í„°ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        converted = []
        for item in data_items:
            prompt = item["prompt"]
            canonical_solution = item["canonical_solution"]
            test_cases = item["test"]
            entry_point = item["entry_point"]
            task_id = item["task_id"]
            
            # Extract function signature from prompt
            func_signature_match = re.search(r'def\s+\w+\([^)]*\):', prompt)
            func_signature = func_signature_match.group(0) if func_signature_match else f"def {entry_point}"
            
            converted.append({
                "input": prompt,
                "additional_context": {
                    "canonical_solution": canonical_solution,
                    "test_cases": test_cases,
                    "entry_point": entry_point,
                    "task_id": task_id
                },
                "answer": func_signature
            })
        return converted

    # ê° ì„¸íŠ¸ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    trainset = convert_to_humaneval_format(train_data)
    valset = convert_to_humaneval_format(val_data)
    testset = convert_to_humaneval_format(test_data)

    return trainset, valset, testset